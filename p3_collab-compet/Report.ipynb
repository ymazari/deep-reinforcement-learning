{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.19 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python\n",
    "!pip -q install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from ddpg_agent import DDPGAgent\n",
    "from workspace_utils import active_session\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "# Loads the environment\n",
    "env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an agent\n",
    "agent = DDPGAgent(state_size=state_size, action_size=action_size, env=env, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/10000 [00:01<2:52:35,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tMax Score: 0.0....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 45/10000 [00:09<46:40,  3.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 45\tMax Score: 0.09000000171363354....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 56/10000 [00:12<50:33,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 56\tMax Score: 0.10000000149011612....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 100/10000 [00:25<49:25,  3.34it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tEpisode Score: 0.0\tMoving Avgs Score: 0.013300000224262476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 200/10000 [00:55<43:35,  3.75it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200\tEpisode Score: 0.0\tMoving Avgs Score: 0.020400000363588335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 300/10000 [01:19<41:21,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 300\tEpisode Score: 0.0\tMoving Avgs Score: 0.0020000000298023225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 400/10000 [01:42<37:03,  4.32it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 400\tEpisode Score: 0.0\tMoving Avgs Score: 0.0010000000149011613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 500/10000 [02:05<36:16,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500\tEpisode Score: 0.0\tMoving Avgs Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 600/10000 [02:28<36:25,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 600\tEpisode Score: 0.0\tMoving Avgs Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 700/10000 [02:53<48:05,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 700\tEpisode Score: 0.0\tMoving Avgs Score: 0.004800000078976154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 800/10000 [03:31<1:23:31,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 800\tEpisode Score: 0.10000000149011612\tMoving Avgs Score: 0.049000000804662706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 804/10000 [03:33<1:48:15,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 804\tMax Score: 0.20000000298023224....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 848/10000 [03:58<3:14:59,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 848\tMax Score: 0.4000000059604645....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 873/10000 [04:15<2:58:04,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 873\tMax Score: 0.5000000074505806....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 900/10000 [04:26<1:00:17,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 900\tEpisode Score: 0.09000000171363354\tMoving Avgs Score: 0.07830000123009086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1000/10000 [05:09<1:26:28,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000\tEpisode Score: 0.10000000149011612\tMoving Avgs Score: 0.05180000081658363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1100/10000 [06:02<1:14:51,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1100\tEpisode Score: 0.09000000171363354\tMoving Avgs Score: 0.08710000144317746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1200/10000 [06:41<1:19:57,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1200\tEpisode Score: 0.09000000171363354\tMoving Avgs Score: 0.047000000774860384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1300/10000 [07:39<1:26:30,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1300\tEpisode Score: 0.10000000149011612\tMoving Avgs Score: 0.10080000162124633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1400/10000 [08:49<1:26:07,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1400\tEpisode Score: 0.10000000149011612\tMoving Avgs Score: 0.11820000182837248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1425/10000 [09:10<4:07:14,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1425\tMax Score: 0.6000000089406967....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1488/10000 [10:01<5:43:56,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1488\tMax Score: 0.800000011920929....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1500/10000 [10:14<1:45:47,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1500\tEpisode Score: 0.09000000171363354\tMoving Avgs Score: 0.1309000020287931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1518/10000 [10:34<5:57:05,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1518\tMax Score: 1.1000000163912773....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1554/10000 [11:46<9:56:27,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1554\tMax Score: 1.2000000178813934....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1556/10000 [12:02<15:42:14,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1556\tMax Score: 2.0000000298023224....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1559/10000 [12:27<19:32:49,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1559\tMax Score: 2.3000000342726707....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1591/10000 [14:10<13:02:36,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1591\tMax Score: 2.500000037252903....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1592/10000 [14:27<20:51:56,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1592\tMax Score: 2.600000038743019....checkpoint....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1600/10000 [15:30<23:11:14,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1600\tEpisode Score: 2.600000038743019\tMoving Avgs Score: 0.48910000732168557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1602/10000 [15:38<15:55:51,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Solved in Episode 1603\tEpisode Score: 0.7000000104308128\tMoving Average Score: 0.5011000075004994\n"
     ]
    }
   ],
   "source": [
    "# Train it\n",
    "with active_session():\n",
    "    scores, average_scores = agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f546377cc88>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores, label=\"Episode Scores\")\n",
    "plt.plot(np.arange(1, len(average_scores)+1), average_scores, label=\"Average Scores (over 100 episodes)\")\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor(\n",
      "  (fc1): Linear(in_features=24, out_features=400, bias=True)\n",
      "  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=400, out_features=300, bias=True)\n",
      "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=300, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Show the actor's architecture\n",
    "print(agent.actor_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic(\n",
      "  (fc1): Linear(in_features=24, out_features=400, bias=True)\n",
      "  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=402, out_features=300, bias=True)\n",
      "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Show the critic's architecture\n",
    "print(agent.critic_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Report: Collaboration and Competition\n",
    "For more details about how to execute the code, look at “Instructions” and “Files” sections in README.md.\n",
    "\n",
    "## Learning Algorithm\n",
    "In this project, I used the Deep Deterministic Policy Gradients (DDPG) algorithm with 2 agents (same ad for project 2).\n",
    "The code itself is based on the DDPG with OpenAI Gym's BipedalWalker environment, from Udacity’s repo (https://github.com/udacity/deep-reinforcement-learning/tree/master/ddpg-bipedal).  \n",
    "The agent consists of an Actor network, which takes the state as input and returns a deterministic action; and a Critic network which tries to approximate the value function and returns the action-value for the action taken by the actor.\n",
    "\n",
    "The two agants share the same replay buffer, and they share the same actor and crtitic networks, making them work in collaboration mode: Any learning from one of the agents is directly reflected to the other.\n",
    "\n",
    "Furthermore, for each of the actor and critic there are actually two models, a main network and a target network. The target networks are used for calculating the error and are updated less often to avoid oscillations and make the learning more stable.\n",
    "\n",
    "The agent also makes use of experience replay (re-used from the code in a previous assignment), in order to mitigate issues with correlations between successive inputs.\n",
    "\n",
    "While the actor itself returns a deterministic action, some randomness is added to the output to encourage exploration. This random additive noise is generated through an Ornstein-Uhlenbeck process (also re-used from the code from Udacity repo), and is controlled via a decaying hyper-parameter epsilon, so as to encourage exploration initially and then rely more and more on exploitation as the models gets more training.\n",
    "\n",
    "As suggested in the “Benchmark Implementation” section of the course, I changed the code to update the local/main networks 10 times after every 20 timesteps as well as using gradient clipping. Also, I used a “soft-update” for updating the target networks.\n",
    "\n",
    "The training consist in running several episodes:  \n",
    "1) Starting from an initial state  \n",
    "2) Make the agent take an action (with additive noise for exploration)  \n",
    "3) Get the reward and next state for the taken action and add them to the replay buffer  \n",
    "4) After every 20 timesteps, for 10 times:  \n",
    "  - sample data from the replay buffer  \n",
    "  - perform a weight update for the local networks based on the expected and target action-values\n",
    "  - Perform a “soft-update” is used to update the target network parameter every pre-defined number of steps.\n",
    "  - When the requirement average score over 100 episodes at least 30 is satisfied, training is stopped and model weights are saved.\n",
    "\n",
    "## Model Architecture\n",
    "The actor is a fully-connected network with 3 hidden layers and relu as an activation function, and batch normalization to normalize the input states and intermediate inputs to each layer. The normalization improves the learning because the entries in the 33-dimensional state vector have a different meaning and scale. \n",
    "The output is a 2-dimensional vector corresponding to the actions space size, with each action clipped to be in the range [-1, 1]\n",
    "\n",
    "The critic is a fully-connected network with 3 hidden layers and relu as an activation function, and batch normalization to normalize the input states and intermediate inputs to each layer.\n",
    "In addition to the state, the critic network also takes the action vector as an input. The resulting output is a scalar corresponding to the state-action value.  \n",
    "See the above cells for the details.\n",
    "\n",
    "## Hyperparameters\n",
    "The following were used:     \n",
    "LR_ACTOR = 1e-3  # learning rate of Actor  \n",
    "LR_CRITIC = 1e-3  # learning rate of Critic  \n",
    "WEIGHT_DECAY = 0.  # L2 weight decay  \n",
    "GAMMA = 0.99  # discount factor  \n",
    "TAU = 1e-3  # soft update parameter  \n",
    "BATCH_SIZE = 512  # batch size to sample from replay buffer  \n",
    "BUFFER_SIZE = int(1e5)  # max size (capacity) of the replay buffer  \n",
    "LEARN_INTERVAL = 20  \n",
    "LEARN_TIMES = 10    \n",
    "\n",
    "As well as:  \n",
    "fc1_units = 400  \n",
    "fc2_units=300 # Size of hidden units for both actor and critic  \n",
    "\n",
    "Furthermore, I used  \n",
    "Adam optimizer as the optimizer  \n",
    "Mean squared error (torch.nn.functional.mse_loss) as a loss function for the critic.\n",
    "\n",
    "The choice of the initial values for the hyperparameters was based on a previous assignment, and then verified that these values lead to good empirical results\n",
    "\n",
    "## Plot of Rewards\n",
    "We see that after 1603 episods, the agent reaches an average score of 0.5, the desired minimum, and the models’ weights are saved.\n",
    "See the figure above for the plot of the rewards.\n",
    "\n",
    "## Ideas for Future Work\n",
    "- I was actually very surprised to get the 2 agents to learn so quickly and just by re-using the DDPG approach without actual parallelizarion. I watched the agents play the game, and they did play very well, but were not \"competing\" against each other, but rather \"collaborating\" to keep the ball from falling as long as possible. This confirms what is described in the above \"Learning Algorithm\" section.\n",
    "    - So one possible future work is to try with the MADDPG, with each agent having their own actor and possibly critic network, and then watch them \"compete\" against each other.\n",
    "- Another possibility for improvement is to further tune the hyperparameters. For this project I just selected them from previous Udacity assignments and got acceptable results. Doing the tuning may lead the model to fall in a better local minimum resulting in higher rewards, or use a different learning rate which could speed up the learning.\n",
    "- It’s worth trying the other suggested algorithm in the class, AlphaZero"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
